{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils import normalize,toy_data,norm_embed,nmi_score\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from layers import GraphConvolution, InnerProduct\n",
    "from utils import norm_embed\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, batch_size, nfeat, nhid, ndim, mu0, sigma0, fixed):\n",
    "        super(GNN, self).__init__()\n",
    "\n",
    "        self.gc1 = GraphConvolution(batch_size, nfeat, nhid, mu0, sigma0, scale=False)\n",
    "        self.fixed = fixed\n",
    "        if self.fixed:\n",
    "            self.embeddings = GraphConvolution(batch_size, nhid, 2*ndim, mu0, sigma0, scale=True)\n",
    "            self.reconstructions = InnerProduct(2*ndim)\n",
    "        else:\n",
    "            self.embeddings = GraphConvolution(batch_size, nhid, 4 * ndim, mu0, sigma0, scale=True)\n",
    "            self.reconstructions = InnerProduct(4*ndim)\n",
    "        \n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = self.gc1(x, adj)\n",
    "\n",
    "        if self.fixed:\n",
    "            mu = F.relu(self.reconstructions(x))\n",
    "            return mu, x\n",
    "        else:\n",
    "            lr1, lr2 = torch.chunk(x, chunks=2, dim=2)\n",
    "            mu = F.relu(self.reconstructions(lr1))\n",
    "            sigma = F.relu(self.reconstructions(lr2))\n",
    "            return mu, sigma, x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "torch.set_printoptions(sci_mode=False,precision=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='Disables CUDA training.')\n",
    "parser.add_argument('--fastmode', action='store_true', default=False,\n",
    "                    help='Validate during training pass.')\n",
    "parser.add_argument('--seed', type=int, default=426, help='Random seed.')\n",
    "parser.add_argument('--epochs', type=int, default=500,\n",
    "                    help='Number of epochs to train.')\n",
    "parser.add_argument('--lr', type=float, default=0.0001,\n",
    "                    help='Initial learning rate.')\n",
    "parser.add_argument('--weight_decay', type=float, default=10e-4,\n",
    "                    help='Weight decay (L2 loss on parameters).')\n",
    "parser.add_argument('--hidden', type=int, default=16,\n",
    "                    help='Number of hidden units.')\n",
    "parser.add_argument('--ndim', type=int, default=2,\n",
    "                    help='Embeddings dimension.')\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(cite=False,cora=False,pub=False):\n",
    "    \n",
    "    if cite:\n",
    "        df1 = pd.read_csv('data/citeseer/citeseer.edges')\n",
    "        df2 = pd.read_csv('data/citeseer/citeseer.node_labels')\n",
    "        G = nx.from_pandas_edgelist(df1, 'u', 'v','weight',create_using=nx.DiGraph())\n",
    "        adj_list = np.array([nx.adjacency_matrix(G).todense()], dtype=float)\n",
    "    \n",
    "    elif cora:\n",
    "        df1 = pd.read_csv('data/cora/cora.edges')\n",
    "        df2 = pd.read_csv('data/cora/cora.node_labels')\n",
    "        G = nx.from_pandas_edgelist(df1, 'u', 'v','weight',create_using=nx.DiGraph())\n",
    "        adj_list = np.array([nx.adjacency_matrix(G).todense()], dtype=float)\n",
    "    \n",
    "    elif pub:\n",
    "        df1 = pd.read_csv('data/pubmed/pubmed.edges')\n",
    "        df2 = pd.read_csv('data/pubmed/pubmed.node_labels')\n",
    "        G = nx.from_pandas_edgelist(df1, 'u', 'v',create_using=nx.DiGraph())\n",
    "        adj_list = np.array([nx.adjacency_matrix(G).todense()], dtype=float)\n",
    "        \n",
    "    return adj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = load_data(cite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Dimension','SVD', 'GNN Fixed Sigma', 'GNN Flexible Sigma']\n",
    "dims= [10, 20, 30, 40, 50, 60, 70, 80]\n",
    "res_svd = []\n",
    "res_fix = []\n",
    "res_flex = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svdApprox(adj,dim,relu=False):\n",
    "    adj = torch.FloatTensor(adj[0])\n",
    "    U, S, Vh = torch.linalg.svd(adj)\n",
    "    mu = torch.matmul(torch.matmul(U[:, :dim], torch.diag(S[:dim])), Vh[:dim, :])\n",
    "    \n",
    "    embedx = torch.matmul(U[:, :dim],torch.diag(torch.pow(S[:dim], 0.5)))\n",
    "    embedy = torch.transpose(torch.matmul(torch.diag(torch.pow(S[:dim], 0.5)),Vh[:dim, :]),0,1)\n",
    "    \n",
    "    criterion = torch.nn.GaussianNLLLoss()\n",
    "    if relu:\n",
    "        crt = torch.nn.ReLU()\n",
    "        mu = crt(mu)\n",
    "    mse = torch.nn.MSELoss()\n",
    "    mseloss = mse(torch.flatten(mu), torch.flatten(adj))\n",
    "    sig = torch.sqrt(mseloss)\n",
    "    sigma = sig * torch.ones(adj.shape)\n",
    "    loss = criterion(torch.flatten(adj), torch.flatten(mu), torch.flatten(torch.square(sigma)))\n",
    "    \n",
    "    return mu,sigma,loss.item(),embedx,embedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GraphNeuralNet(adj,dim,fixed=False,new=True,features=None,sig_fix=None):\n",
    "    \n",
    "    # Set the random seed\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.cuda:\n",
    "        torch.cuda.manual_seed(args.seed)\n",
    "        \n",
    "    args.ndim = dim\n",
    "    \n",
    "    adj_norm = normalize(adj)\n",
    "\n",
    "    adj = torch.FloatTensor(np.array(adj)).cuda()\n",
    "    \n",
    "    # loss function\n",
    "    criterion = torch.nn.GaussianNLLLoss()\n",
    "    \n",
    "    # NULL Model\n",
    "    mu0 = adj.mean()*torch.ones(adj.shape[1:]).cuda()\n",
    "    sigma0 = adj.std()*torch.ones(adj.shape[1:]).cuda()\n",
    "    with torch.no_grad():\n",
    "        loss0 = criterion(torch.flatten(adj), torch.flatten(mu0), torch.flatten(torch.square(sigma0)))\n",
    "    \n",
    "    if new:\n",
    "        if fixed:\n",
    "            #svd features\n",
    "            svd_mu,svd_sig,svd_loss,svdembedx,svdembedy = svdApprox(adj=adj.cpu(),dim=dim)\n",
    "            features = torch.cat((svdembedx,svdembedy),dim=1)\n",
    "        if not fixed:\n",
    "            sig_flex = torch.ones(features.shape).cuda()*torch.sqrt(sig_fix/dim).cuda()\n",
    "            features = torch.cat((features,sig_flex),dim=1).cuda()\n",
    "        features = features.unsqueeze(dim=0)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    # Model and optimizer  \n",
    "        \n",
    "    model = GNN(batch_size=adj.shape[0],\n",
    "                nfeat=adj.shape[1],\n",
    "                nhid=adj.shape[1],\n",
    "                ndim=args.ndim,\n",
    "                mu0=adj.mean(),\n",
    "                sigma0=adj.std(),\n",
    "                fixed=fixed)\n",
    "\n",
    "    if args.cuda:\n",
    "        model.cuda()\n",
    "        features = features.cuda()\n",
    "        adj = adj.cuda()\n",
    "        adj_norm = adj_norm.cuda()\n",
    "\n",
    "\n",
    "    # Train model\n",
    "    t_total = time.time()\n",
    "    \n",
    "    # NULL Model\n",
    "    mu0 = adj.mean()*torch.ones(adj.shape[1:]).cuda()\n",
    "    sigma0 = adj.std()*torch.ones(adj.shape[1:]).cuda()\n",
    "    with torch.no_grad():\n",
    "        loss0 = criterion(torch.flatten(adj), torch.flatten(mu0), torch.flatten(torch.square(sigma0)))\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(),\n",
    "                           lr=args.lr, weight_decay=args.weight_decay)\n",
    "    \n",
    "    \n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "\n",
    "        t = time.time()\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if fixed:\n",
    "            mu,lr = model(features, adj_norm)\n",
    "            with torch.no_grad():\n",
    "                mse = torch.nn.MSELoss()\n",
    "                mseloss = mse(torch.flatten(mu),torch.flatten(adj))\n",
    "                sig = torch.sqrt(mseloss)\n",
    "            sigma = sig * torch.ones(adj.shape,requires_grad=True).cuda()\n",
    "        else:\n",
    "            mu,sigma,lr = model(features, adj_norm)\n",
    "        \n",
    "        \n",
    "        loss = criterion(torch.flatten(adj), torch.flatten(mu), torch.flatten(torch.square(sigma))) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch == 0:\n",
    "            best_loss = loss\n",
    "            best_lr = lr\n",
    "            if fixed:\n",
    "                best_sig = sig\n",
    "        else:\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_lr = lr\n",
    "                if fixed:\n",
    "                    best_sig = sig\n",
    "\n",
    "        if epoch == 0 or (epoch+1) % 100 == 0:\n",
    "            print('Epoch: {:04d}'.format(epoch + 1),\n",
    "                  'loss: {:.8f}'.format(best_loss.item()))\n",
    "            \n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "    \n",
    "    if new and fixed:\n",
    "        return mu,best_loss.item(),loss0,best_lr,best_sig,svd_loss\n",
    "    elif fixed:\n",
    "        return mu,best_loss.item(),loss0,best_lr,best_sig\n",
    "    else:\n",
    "        return mu,best_loss.item(),loss0,best_lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed Sigma dim 10\n",
      "Epoch: 0001 loss: -3.43291855\n",
      "Epoch: 0100 loss: -3.45384145\n",
      "Epoch: 0200 loss: -3.50535464\n",
      "Epoch: 0300 loss: -3.58160233\n",
      "Epoch: 0400 loss: -3.65916491\n",
      "Epoch: 0500 loss: -3.72363663\n",
      "Optimization Finished!\n",
      "Total time elapsed: 32.7909s\n",
      "Epoch: 0001 loss: -3.72363663\n",
      "Epoch: 0100 loss: -3.88599634\n",
      "Epoch: 0200 loss: -3.90735197\n",
      "Epoch: 0300 loss: -3.90814328\n",
      "Epoch: 0400 loss: -3.90833855\n",
      "Epoch: 0500 loss: -3.90833855\n",
      "Optimization Finished!\n",
      "Total time elapsed: 35.2674s\n",
      "Fixed Sigma dim 20\n",
      "Epoch: 0001 loss: -3.45997477\n",
      "Epoch: 0100 loss: -3.51552105\n",
      "Epoch: 0200 loss: -3.71562576\n",
      "Epoch: 0300 loss: -3.88085961\n",
      "Epoch: 0400 loss: -3.92020988\n",
      "Epoch: 0500 loss: -3.93137622\n",
      "Optimization Finished!\n",
      "Total time elapsed: 36.4961s\n",
      "Epoch: 0001 loss: -3.93137622\n",
      "Epoch: 0100 loss: -3.97194052\n",
      "Epoch: 0200 loss: -3.97250462\n",
      "Epoch: 0300 loss: -3.97252059\n",
      "Epoch: 0400 loss: -3.97252321\n",
      "Epoch: 0500 loss: -3.97252321\n",
      "Optimization Finished!\n",
      "Total time elapsed: 37.4777s\n",
      "Fixed Sigma dim 30\n",
      "Epoch: 0001 loss: -3.48277664\n",
      "Epoch: 0100 loss: -3.57629299\n",
      "Epoch: 0200 loss: -3.86726213\n",
      "Epoch: 0300 loss: -3.96740627\n",
      "Epoch: 0400 loss: -3.98258805\n",
      "Epoch: 0500 loss: -3.98787308\n",
      "Optimization Finished!\n",
      "Total time elapsed: 37.3185s\n",
      "Epoch: 0001 loss: -3.98787308\n",
      "Epoch: 0100 loss: -4.01442146\n",
      "Epoch: 0200 loss: -4.01455641\n",
      "Epoch: 0300 loss: -4.01455832\n",
      "Epoch: 0400 loss: -4.01456022\n",
      "Epoch: 0500 loss: -4.01456022\n",
      "Optimization Finished!\n",
      "Total time elapsed: 37.0815s\n",
      "Fixed Sigma dim 40\n",
      "Epoch: 0001 loss: -3.50370717\n",
      "Epoch: 0100 loss: -3.63717294\n",
      "Epoch: 0200 loss: -3.99134684\n",
      "Epoch: 0300 loss: -4.04470968\n",
      "Epoch: 0400 loss: -4.05279446\n",
      "Epoch: 0500 loss: -4.05609035\n",
      "Optimization Finished!\n",
      "Total time elapsed: 38.3892s\n",
      "Epoch: 0001 loss: -4.05609035\n",
      "Epoch: 0100 loss: -4.07697821\n",
      "Epoch: 0200 loss: -4.07703686\n",
      "Epoch: 0300 loss: -4.07703924\n",
      "Epoch: 0400 loss: -4.07703972\n",
      "Epoch: 0500 loss: -4.07703972\n",
      "Optimization Finished!\n",
      "Total time elapsed: 37.9833s\n",
      "Fixed Sigma dim 50\n",
      "Epoch: 0001 loss: -3.52288866\n",
      "Epoch: 0100 loss: -3.69727659\n",
      "Epoch: 0200 loss: -4.07913113\n",
      "Epoch: 0300 loss: -4.11268854\n",
      "Epoch: 0400 loss: -4.11849737\n",
      "Epoch: 0500 loss: -4.12102890\n",
      "Optimization Finished!\n",
      "Total time elapsed: 36.9882s\n",
      "Epoch: 0001 loss: -4.12102890\n",
      "Epoch: 0100 loss: -4.13929224\n",
      "Epoch: 0200 loss: -4.13932276\n",
      "Epoch: 0300 loss: -4.13932467\n",
      "Epoch: 0400 loss: -4.13932514\n",
      "Epoch: 0500 loss: -4.13932514\n",
      "Optimization Finished!\n",
      "Total time elapsed: 36.9853s\n",
      "Fixed Sigma dim 60\n",
      "Epoch: 0001 loss: -3.54042315\n",
      "Epoch: 0100 loss: -3.73465061\n",
      "Epoch: 0200 loss: -4.09388971\n",
      "Epoch: 0300 loss: -4.11690187\n",
      "Epoch: 0400 loss: -4.12152195\n",
      "Epoch: 0500 loss: -4.12359858\n",
      "Optimization Finished!\n",
      "Total time elapsed: 36.8555s\n",
      "Epoch: 0001 loss: -4.12359858\n",
      "Epoch: 0100 loss: -4.14029932\n",
      "Epoch: 0200 loss: -4.14032269\n",
      "Epoch: 0300 loss: -4.14032936\n",
      "Epoch: 0400 loss: -4.14032936\n",
      "Epoch: 0500 loss: -4.14032984\n",
      "Optimization Finished!\n",
      "Total time elapsed: 36.7925s\n",
      "Fixed Sigma dim 70\n",
      "Epoch: 0001 loss: -3.55713248\n",
      "Epoch: 0100 loss: -3.78561115\n",
      "Epoch: 0200 loss: -4.19439983\n",
      "Epoch: 0300 loss: -4.21132421\n",
      "Epoch: 0400 loss: -4.21517849\n",
      "Epoch: 0500 loss: -4.21697855\n",
      "Optimization Finished!\n",
      "Total time elapsed: 37.0607s\n",
      "Epoch: 0001 loss: -4.21697855\n",
      "Epoch: 0100 loss: -4.23178101\n",
      "Epoch: 0200 loss: -4.23179388\n",
      "Epoch: 0300 loss: -4.23179388\n",
      "Epoch: 0400 loss: -4.23179388\n",
      "Epoch: 0500 loss: -4.23179388\n",
      "Optimization Finished!\n",
      "Total time elapsed: 37.1412s\n",
      "Fixed Sigma dim 80\n",
      "Epoch: 0001 loss: -3.57287598\n",
      "Epoch: 0100 loss: -3.82325912\n",
      "Epoch: 0200 loss: -4.19820881\n",
      "Epoch: 0300 loss: -4.21216202\n",
      "Epoch: 0400 loss: -4.21569920\n",
      "Epoch: 0500 loss: -4.21739674\n",
      "Optimization Finished!\n",
      "Total time elapsed: 37.5457s\n",
      "Epoch: 0001 loss: -4.21739674\n",
      "Epoch: 0100 loss: -4.23178053\n",
      "Epoch: 0200 loss: -4.23179197\n",
      "Epoch: 0300 loss: -4.23179197\n",
      "Epoch: 0400 loss: -4.23179293\n",
      "Epoch: 0500 loss: -4.23179388\n",
      "Optimization Finished!\n",
      "Total time elapsed: 37.4123s\n"
     ]
    }
   ],
   "source": [
    "for dim in dims:\n",
    "    print(\"Fixed Sigma dim {}\".format(dim))\n",
    "\n",
    "    mu,loss,loss0,lr,sigma,svd_loss = GraphNeuralNet(adj=adj,dim=dim,fixed=True)\n",
    "    mu,loss,loss0,lr,sigma = GraphNeuralNet(adj=adj,dim=dim,fixed=True,new=False,features=lr.detach())\n",
    "\n",
    "    res_svd.append(svd_loss)\n",
    "    res_fix.append(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed Sigma dim 5\n",
      "Epoch: 0001 loss: -3.41526914\n",
      "Epoch: 0100 loss: -3.42693615\n",
      "Epoch: 0200 loss: -3.43150401\n",
      "Epoch: 0300 loss: -3.43647790\n",
      "Epoch: 0400 loss: -3.44343209\n",
      "Epoch: 0500 loss: -3.45202255\n",
      "Optimization Finished!\n",
      "Total time elapsed: 31.4144s\n",
      "Epoch: 0001 loss: -3.45202255\n",
      "Epoch: 0100 loss: -3.51444554\n",
      "Epoch: 0200 loss: -3.55720901\n",
      "Epoch: 0300 loss: -3.57400513\n",
      "Epoch: 0400 loss: -3.58279037\n",
      "Epoch: 0500 loss: -3.58772230\n",
      "Optimization Finished!\n",
      "Total time elapsed: 31.4583s\n",
      "Flexible Sigma dim 10\n",
      "Epoch: 0001 loss: -3.58772230\n",
      "Epoch: 0100 loss: -4.23003101\n",
      "Epoch: 0200 loss: -4.38593912\n",
      "Epoch: 0300 loss: -4.44870615\n",
      "Epoch: 0400 loss: -4.49102354\n",
      "Epoch: 0500 loss: -4.50907850\n",
      "Optimization Finished!\n",
      "Total time elapsed: 20.1826s\n",
      "Epoch: 0001 loss: -4.50907850\n",
      "Epoch: 0100 loss: -4.50907850\n",
      "Epoch: 0200 loss: -4.50907850\n",
      "Epoch: 0300 loss: -4.50907850\n",
      "Epoch: 0400 loss: -4.50907850\n",
      "Epoch: 0500 loss: -4.50907850\n",
      "Optimization Finished!\n",
      "Total time elapsed: 20.5418s\n",
      "Fixed Sigma dim 10\n",
      "Epoch: 0001 loss: -3.43291855\n",
      "Epoch: 0100 loss: -3.45384145\n",
      "Epoch: 0200 loss: -3.50535464\n",
      "Epoch: 0300 loss: -3.58160233\n",
      "Epoch: 0400 loss: -3.65916491\n",
      "Epoch: 0500 loss: -3.72363663\n",
      "Optimization Finished!\n",
      "Total time elapsed: 34.0333s\n",
      "Epoch: 0001 loss: -3.72363663\n",
      "Epoch: 0100 loss: -3.88599634\n",
      "Epoch: 0200 loss: -3.90735197\n",
      "Epoch: 0300 loss: -3.90814328\n",
      "Epoch: 0400 loss: -3.90833855\n",
      "Epoch: 0500 loss: -3.90833855\n",
      "Optimization Finished!\n",
      "Total time elapsed: 34.7334s\n",
      "Flexible Sigma dim 20\n",
      "Epoch: 0001 loss: -3.90833902\n",
      "Epoch: 0100 loss: -5.72190666\n",
      "Epoch: 0200 loss: -5.78042746\n",
      "Epoch: 0300 loss: -5.79645348\n",
      "Epoch: 0400 loss: -5.80689907\n",
      "Epoch: 0500 loss: -5.81395674\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.3151s\n",
      "Epoch: 0001 loss: -5.81395674\n",
      "Epoch: 0100 loss: -5.81395674\n",
      "Epoch: 0200 loss: -5.81395674\n",
      "Epoch: 0300 loss: -5.81525421\n",
      "Epoch: 0400 loss: -5.82499695\n",
      "Epoch: 0500 loss: -5.82786512\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.2955s\n",
      "Fixed Sigma dim 15\n",
      "Epoch: 0001 loss: -3.44702053\n",
      "Epoch: 0100 loss: -3.48647594\n",
      "Epoch: 0200 loss: -3.61335826\n",
      "Epoch: 0300 loss: -3.77310324\n",
      "Epoch: 0400 loss: -3.86808920\n",
      "Epoch: 0500 loss: -3.89936399\n",
      "Optimization Finished!\n",
      "Total time elapsed: 35.2547s\n",
      "Epoch: 0001 loss: -3.89936399\n",
      "Epoch: 0100 loss: -3.96532869\n",
      "Epoch: 0200 loss: -3.96709919\n",
      "Epoch: 0300 loss: -3.96748853\n",
      "Epoch: 0400 loss: -3.96749997\n",
      "Epoch: 0500 loss: -3.96750236\n",
      "Optimization Finished!\n",
      "Total time elapsed: 35.4296s\n",
      "Flexible Sigma dim 30\n",
      "Epoch: 0001 loss: -3.96750188\n",
      "Epoch: 0100 loss: -5.99344397\n",
      "Epoch: 0200 loss: -6.02798510\n",
      "Epoch: 0300 loss: -6.04111767\n",
      "Epoch: 0400 loss: -6.04813194\n",
      "Epoch: 0500 loss: -6.05240011\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.1838s\n",
      "Epoch: 0001 loss: -6.05240011\n",
      "Epoch: 0100 loss: -6.05418873\n",
      "Epoch: 0200 loss: -6.06642056\n",
      "Epoch: 0300 loss: -6.07142210\n",
      "Epoch: 0400 loss: -6.07388067\n",
      "Epoch: 0500 loss: -6.07398367\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.2269s\n",
      "Fixed Sigma dim 20\n",
      "Epoch: 0001 loss: -3.45997477\n",
      "Epoch: 0100 loss: -3.51552105\n",
      "Epoch: 0200 loss: -3.71562576\n",
      "Epoch: 0300 loss: -3.88085961\n",
      "Epoch: 0400 loss: -3.92020988\n",
      "Epoch: 0500 loss: -3.93137622\n",
      "Optimization Finished!\n",
      "Total time elapsed: 36.0744s\n",
      "Epoch: 0001 loss: -3.93137622\n",
      "Epoch: 0100 loss: -3.97194052\n",
      "Epoch: 0200 loss: -3.97250462\n",
      "Epoch: 0300 loss: -3.97252059\n",
      "Epoch: 0400 loss: -3.97252321\n",
      "Epoch: 0500 loss: -3.97252321\n",
      "Optimization Finished!\n",
      "Total time elapsed: 35.5809s\n",
      "Flexible Sigma dim 40\n",
      "Epoch: 0001 loss: -3.97252250\n",
      "Epoch: 0100 loss: -6.02396774\n",
      "Epoch: 0200 loss: -6.05125713\n",
      "Epoch: 0300 loss: -6.06290293\n",
      "Epoch: 0400 loss: -6.06943035\n",
      "Epoch: 0500 loss: -6.07392597\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.2830s\n",
      "Epoch: 0001 loss: -6.07392597\n",
      "Epoch: 0100 loss: -6.08097172\n",
      "Epoch: 0200 loss: -6.08859205\n",
      "Epoch: 0300 loss: -6.09344482\n",
      "Epoch: 0400 loss: -6.09595537\n",
      "Epoch: 0500 loss: -6.09649324\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.2713s\n",
      "Fixed Sigma dim 25\n",
      "Epoch: 0001 loss: -3.47187567\n",
      "Epoch: 0100 loss: -3.55206227\n",
      "Epoch: 0200 loss: -3.82031131\n",
      "Epoch: 0300 loss: -3.95507812\n",
      "Epoch: 0400 loss: -3.97615170\n",
      "Epoch: 0500 loss: -3.98326540\n",
      "Optimization Finished!\n",
      "Total time elapsed: 36.2812s\n",
      "Epoch: 0001 loss: -3.98326540\n",
      "Epoch: 0100 loss: -4.01435614\n",
      "Epoch: 0200 loss: -4.01455641\n",
      "Epoch: 0300 loss: -4.01455879\n",
      "Epoch: 0400 loss: -4.01456022\n",
      "Epoch: 0500 loss: -4.01456070\n",
      "Optimization Finished!\n",
      "Total time elapsed: 35.9316s\n",
      "Flexible Sigma dim 50\n",
      "Epoch: 0001 loss: -4.01456022\n",
      "Epoch: 0100 loss: -6.09127855\n",
      "Epoch: 0200 loss: -6.11912727\n",
      "Epoch: 0300 loss: -6.13093901\n",
      "Epoch: 0400 loss: -6.13720608\n",
      "Epoch: 0500 loss: -6.14135885\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.3591s\n",
      "Epoch: 0001 loss: -6.14135885\n",
      "Epoch: 0100 loss: -6.14978361\n",
      "Epoch: 0200 loss: -6.15693951\n",
      "Epoch: 0300 loss: -6.16154480\n",
      "Epoch: 0400 loss: -6.16373110\n",
      "Epoch: 0500 loss: -6.16373110\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.2789s\n",
      "Fixed Sigma dim 30\n",
      "Epoch: 0001 loss: -3.48277664\n",
      "Epoch: 0100 loss: -3.57629299\n",
      "Epoch: 0200 loss: -3.86726213\n",
      "Epoch: 0300 loss: -3.96740627\n",
      "Epoch: 0400 loss: -3.98258805\n",
      "Epoch: 0500 loss: -3.98787308\n",
      "Optimization Finished!\n",
      "Total time elapsed: 36.5467s\n",
      "Epoch: 0001 loss: -3.98787308\n",
      "Epoch: 0100 loss: -4.01442146\n",
      "Epoch: 0200 loss: -4.01455641\n",
      "Epoch: 0300 loss: -4.01455832\n",
      "Epoch: 0400 loss: -4.01456022\n",
      "Epoch: 0500 loss: -4.01456022\n",
      "Optimization Finished!\n",
      "Total time elapsed: 36.0082s\n",
      "Flexible Sigma dim 60\n",
      "Epoch: 0001 loss: -4.01455784\n",
      "Epoch: 0100 loss: -6.09272289\n",
      "Epoch: 0200 loss: -6.11973190\n",
      "Epoch: 0300 loss: -6.13118124\n",
      "Epoch: 0400 loss: -6.13731813\n",
      "Epoch: 0500 loss: -6.14137077\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.4132s\n",
      "Epoch: 0001 loss: -6.14137077\n",
      "Epoch: 0100 loss: -6.15020180\n",
      "Epoch: 0200 loss: -6.15738058\n",
      "Epoch: 0300 loss: -6.16209793\n",
      "Epoch: 0400 loss: -6.16413975\n",
      "Epoch: 0500 loss: -6.16413975\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.3267s\n",
      "Fixed Sigma dim 35\n",
      "Epoch: 0001 loss: -3.49347305\n",
      "Epoch: 0100 loss: -3.61169839\n",
      "Epoch: 0200 loss: -3.96426773\n",
      "Epoch: 0300 loss: -4.03980875\n",
      "Epoch: 0400 loss: -4.05022144\n",
      "Epoch: 0500 loss: -4.05422878\n",
      "Optimization Finished!\n",
      "Total time elapsed: 36.6965s\n",
      "Epoch: 0001 loss: -4.05422878\n",
      "Epoch: 0100 loss: -4.07739592\n",
      "Epoch: 0200 loss: -4.07748175\n",
      "Epoch: 0300 loss: -4.07748413\n",
      "Epoch: 0400 loss: -4.07748413\n",
      "Epoch: 0500 loss: -4.07748461\n",
      "Optimization Finished!\n",
      "Total time elapsed: 36.4487s\n",
      "Flexible Sigma dim 70\n",
      "Epoch: 0001 loss: -4.07748461\n",
      "Epoch: 0100 loss: -6.22024727\n",
      "Epoch: 0200 loss: -6.24135256\n",
      "Epoch: 0300 loss: -6.25135088\n",
      "Epoch: 0400 loss: -6.25703669\n",
      "Epoch: 0500 loss: -6.26075315\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.9639s\n",
      "Epoch: 0001 loss: -6.26075315\n",
      "Epoch: 0100 loss: -6.26075315\n",
      "Epoch: 0200 loss: -6.26533794\n",
      "Epoch: 0300 loss: -6.27412224\n",
      "Epoch: 0400 loss: -6.27904081\n",
      "Epoch: 0500 loss: -6.27973461\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.8177s\n",
      "Fixed Sigma dim 40\n",
      "Epoch: 0001 loss: -3.50370717\n",
      "Epoch: 0100 loss: -3.63717294\n",
      "Epoch: 0200 loss: -3.99134684\n",
      "Epoch: 0300 loss: -4.04470968\n",
      "Epoch: 0400 loss: -4.05279446\n",
      "Epoch: 0500 loss: -4.05609035\n",
      "Optimization Finished!\n",
      "Total time elapsed: 36.5750s\n",
      "Epoch: 0001 loss: -4.05609035\n",
      "Epoch: 0100 loss: -4.07697821\n",
      "Epoch: 0200 loss: -4.07703686\n",
      "Epoch: 0300 loss: -4.07703924\n",
      "Epoch: 0400 loss: -4.07703972\n",
      "Epoch: 0500 loss: -4.07703972\n",
      "Optimization Finished!\n",
      "Total time elapsed: 36.6585s\n",
      "Flexible Sigma dim 80\n",
      "Epoch: 0001 loss: -4.07703924\n",
      "Epoch: 0100 loss: -6.21795702\n",
      "Epoch: 0200 loss: -6.23971939\n",
      "Epoch: 0300 loss: -6.24972820\n",
      "Epoch: 0400 loss: -6.25539637\n",
      "Epoch: 0500 loss: -6.25915670\n",
      "Optimization Finished!\n",
      "Total time elapsed: 24.0220s\n",
      "Epoch: 0001 loss: -6.25915670\n",
      "Epoch: 0100 loss: -6.25915670\n",
      "Epoch: 0200 loss: -6.26671696\n",
      "Epoch: 0300 loss: -6.27362156\n",
      "Epoch: 0400 loss: -6.27752113\n",
      "Epoch: 0500 loss: -6.27882624\n",
      "Optimization Finished!\n",
      "Total time elapsed: 23.9088s\n"
     ]
    }
   ],
   "source": [
    "for dim in dims:\n",
    "    dim = int(dim/2)\n",
    "    print(\"Fixed Sigma dim {}\".format(dim))\n",
    "\n",
    "    mu,loss,loss0,lr,sigma, _ = GraphNeuralNet(adj=adj,dim=dim,fixed=True)\n",
    "    mu,loss,loss0,lr,sigma = GraphNeuralNet(adj=adj,dim=dim,fixed=True,new=False,features=lr.detach())\n",
    "    \n",
    "    print(\"Flexible Sigma dim {}\".format(dim*2))\n",
    "    args.lr *= 0.1\n",
    "\n",
    "    mu,loss,loss0,lr = GraphNeuralNet(adj=adj,dim=dim,new=True,features=lr[0].detach(),sig_fix=sigma)\n",
    "    mu,loss,loss0,lr = GraphNeuralNet(adj=adj,dim=dim,new=False,features=lr.detach())\n",
    "    \n",
    "    args.lr *= 10\n",
    "    \n",
    "    res_flex.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [dims, res_svd, res_fix, res_flex]\n",
    "df = pd.DataFrame(columns=names)\n",
    "df[names[0]] = dims\n",
    "df[names[1]] = res_svd\n",
    "df[names[2]] = res_fix\n",
    "df[names[3]] = res_flex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dimension</th>\n",
       "      <th>SVD</th>\n",
       "      <th>GNN Fixed Sigma</th>\n",
       "      <th>GNN Flexible Sigma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>-3.431473</td>\n",
       "      <td>-3.908339</td>\n",
       "      <td>-4.509079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>-3.457459</td>\n",
       "      <td>-3.972523</td>\n",
       "      <td>-5.827865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>-3.479424</td>\n",
       "      <td>-4.014560</td>\n",
       "      <td>-6.073984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>-3.498844</td>\n",
       "      <td>-4.077040</td>\n",
       "      <td>-6.096493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>-3.516556</td>\n",
       "      <td>-4.139325</td>\n",
       "      <td>-6.163731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>-3.533546</td>\n",
       "      <td>-4.140330</td>\n",
       "      <td>-6.164140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>-3.549839</td>\n",
       "      <td>-4.231794</td>\n",
       "      <td>-6.279735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>-3.565300</td>\n",
       "      <td>-4.231794</td>\n",
       "      <td>-6.278826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dimension       SVD  GNN Fixed Sigma  GNN Flexible Sigma\n",
       "0         10 -3.431473        -3.908339           -4.509079\n",
       "1         20 -3.457459        -3.972523           -5.827865\n",
       "2         30 -3.479424        -4.014560           -6.073984\n",
       "3         40 -3.498844        -4.077040           -6.096493\n",
       "4         50 -3.516556        -4.139325           -6.163731\n",
       "5         60 -3.533546        -4.140330           -6.164140\n",
       "6         70 -3.549839        -4.231794           -6.279735\n",
       "7         80 -3.565300        -4.231794           -6.278826"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1b47ac80c40>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dims,res_fix,label=\"Fixed Sigma\")\n",
    "plt.plot(dims,res_flex,label=\"Flexible Sigma\")\n",
    "plt.plot(dims,res_svd,label=\"SVD\")\n",
    "plt.xlabel(\"dim\")\n",
    "plt.ylabel(\"NLL\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
